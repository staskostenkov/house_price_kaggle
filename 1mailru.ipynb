{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://habr.com/ru/company/ods/blog/328372/\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "\n",
    "#for log-loss \n",
    "labels=[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all time is -  0.0002353191375732422 (sec)\n",
      "local time is -  0.00018477439880371094 (sec)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "tik = time()\n",
    "tik_local = time()\n",
    "\n",
    "def mytime(tik_local):\n",
    "    tak = time()\n",
    "    print('all time is - ', tak-tik, '(sec)')\n",
    "    print('local time is - ', tak-tik_local, '(sec)')\n",
    "    return tak\n",
    "\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all time is -  0.00025963783264160156 (sec)\n",
      "local time is -  0.012349605560302734 (sec)\n"
     ]
    }
   ],
   "source": [
    "# подсчет строк в файле train.tar.gz\n",
    "# 29 989 753\n",
    "#CPU times: user 5min 51s, sys: 9.14 s, total: 6min 1s\n",
    "#Wall time: 6min 5s\n",
    "\n",
    "# подсчет строк в файле test.tar.gz\n",
    "# 1 317 220\n",
    "\n",
    "\n",
    "import tarfile as tf\n",
    "import gzip as gz\n",
    "#from StringIO import StringIO\n",
    "\n",
    "tik = time()\n",
    "\n",
    "infile = 'mailru_data/materials/train.tar.gz'\n",
    "def linecount(infile, member):\n",
    "    lc = 0\n",
    "    with gz.GzipFile(infile) as zipf:\n",
    "        with tf.TarFile(fileobj=zipf) as tarf:\n",
    "            dataf = tarf.extractfile(member)\n",
    "            while dataf.readline():\n",
    "               lc += 1 \n",
    "            dataf.close()       \n",
    "    return lc\n",
    "#print(linecount(infile, 'train.csv'))\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determinate train to numeric and categoric data\n",
    "# Take analysis of numeric and categorical columns\n",
    "def columns_len(all_data):\n",
    "    numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "    start_len_num = len(numeric_feats)\n",
    "    print('len of the numeric_feats is: ', start_len_num)\n",
    "\n",
    "    categorical_feats = all_data.dtypes[all_data.dtypes == \"object\"].index\n",
    "    start_len_cat = len(categorical_feats)\n",
    "    print('len of the categorical_feats is: ', start_len_cat)\n",
    "    print('total len of all_data_feats is: ', len(all_data.columns))\n",
    "    return numeric_feats, categorical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique Data Analysis\n",
    "def unique_analysis(all_data, unique_part):\n",
    "    col_for_drop = []\n",
    "    for col in all_data.columns:\n",
    "        if (np.max(all_data[col].value_counts())/len(all_data[col]))>unique_part:\n",
    "            print(col,np.max(all_data[col].value_counts()), ' of ', len(all_data[col]), ' per cent is ', \n",
    "                  np.max(all_data[col].value_counts())*100//len(all_data[col]),'%')\n",
    "            col_for_drop.append(col)\n",
    "    print\n",
    "    return col_for_drop\n",
    "\n",
    "#aa = unique_analysis(0.8)\n",
    "#print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_columns(all_data):\n",
    "    cat_cols = [c for c in all_data.columns if all_data[c].dtype.name == 'object']\n",
    "    num_cols   = [c for c in all_data.columns if all_data[c].dtype.name != 'object']\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "#print (columns_len.numeric_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузка данных**\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ train shape -----\n",
      "train.csv\n",
      "19\n",
      "(4999, 19)\n",
      "------ test shape -----\n",
      "test.csv\n",
      "(4000, 19)\n",
      "-----------------------\n",
      "all time is -  0.0896143913269043 (sec)\n",
      "local time is -  0.0893547534942627 (sec)\n",
      "CPU times: user 51.1 ms, sys: 196 µs, total: 51.3 ms\n",
      "Wall time: 52.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 1min 51s\n",
    "nrows = 5*10**3\n",
    "#nrows = 29989753   #29 989 753\n",
    "\n",
    "train = pd.read_csv('mailru_data/materials/train.tar.gz', compression='gzip', header=0, sep=';', quotechar='\"', nrows=nrows)\n",
    "train = train[:-1]\n",
    "#train = train.drop([29989752])\n",
    "\n",
    "print('------ train shape -----')\n",
    "print(train.columns[0])\n",
    "print(len(train.columns))\n",
    "print(train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Analyst of test dataframe\n",
    "nrows_test = 4*10**3\n",
    "#nrows_test= 1317220  #1 317 220\n",
    "\n",
    "test = pd.read_csv('mailru_data/materials/test-data.tar.gz', compression='gzip', header=0, sep=',', quotechar='\"', nrows=nrows_test)\n",
    "test.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "\n",
    "print('------ test shape -----')\n",
    "print(test.columns[0])\n",
    "print(test.shape)\n",
    "print('-----------------------')\n",
    "\n",
    "tik_local = mytime(tik_local)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**datasets ans targets**\n",
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len -  4999 test len -  4000\n",
      "all_data size is : (8999, 17)\n",
      "all time is -  0.11810302734375 (sec)\n",
      "local time is -  0.028488636016845703 (sec)\n"
     ]
    }
   ],
   "source": [
    "#Отделение столбца таргета и соединения тренировочной и тестовой части для общей обработки данных\n",
    "\n",
    "train.rename_axis('Id')\n",
    "test.rename_axis('Id')\n",
    "\n",
    "#print(train[:5])\n",
    "train_ID = train['train.csv']\n",
    "test_ID = test['test.csv']\n",
    "\n",
    "train.drop('train.csv', axis = 1, inplace = True)\n",
    "test.drop(\"test.csv\", axis = 1, inplace = True)\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train['label'].values\n",
    "y_test = test['label'].values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['label'], axis=1, inplace=True)\n",
    "print('train len - ',ntrain, 'test len - ',ntest)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))\n",
    "#print(all_data[:3])\n",
    "\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train & test analisyst**\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     int64\n",
       "C1        int64\n",
       "C2        int64\n",
       "C3        int64\n",
       "C4        int64\n",
       "C5        int64\n",
       "C6        int64\n",
       "C7        int64\n",
       "C8        int64\n",
       "C9        int64\n",
       "C10       int64\n",
       "CG1      object\n",
       "CG2      object\n",
       "CG3      object\n",
       "l1        int64\n",
       "l2        int64\n",
       "C11       int64\n",
       "C12       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>CG1</th>\n",
       "      <th>CG2</th>\n",
       "      <th>CG3</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2733540231</td>\n",
       "      <td>3500392421</td>\n",
       "      <td>4454</td>\n",
       "      <td>15573</td>\n",
       "      <td>11</td>\n",
       "      <td>995</td>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>15</td>\n",
       "      <td>671</td>\n",
       "      <td>384,382,96,88,185,49,385,268,448,438,279,420,1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1964843810</td>\n",
       "      <td>1232327635</td>\n",
       "      <td>2081</td>\n",
       "      <td>2547</td>\n",
       "      <td>11</td>\n",
       "      <td>995</td>\n",
       "      <td>2</td>\n",
       "      <td>361</td>\n",
       "      <td>15</td>\n",
       "      <td>802</td>\n",
       "      <td>96,49,385,268,107,438,418,124,357,17,435,130,3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>660357674</td>\n",
       "      <td>2066571765</td>\n",
       "      <td>602</td>\n",
       "      <td>29581</td>\n",
       "      <td>29</td>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>468</td>\n",
       "      <td>15</td>\n",
       "      <td>758</td>\n",
       "      <td>170,169,205,204,176,252,243,382,98,220,222,181...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2962648192</td>\n",
       "      <td>2373358995</td>\n",
       "      <td>4018</td>\n",
       "      <td>36969</td>\n",
       "      <td>30</td>\n",
       "      <td>995</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>273,205,383,382,381,219,216,215,225,49,47,54,3...</td>\n",
       "      <td>28071,6916,9108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1822613420</td>\n",
       "      <td>446973819</td>\n",
       "      <td>2081</td>\n",
       "      <td>23457</td>\n",
       "      <td>35</td>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>15</td>\n",
       "      <td>821</td>\n",
       "      <td>268,419,357,18,331,59,57,99,154,155,76,412,122...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          C1          C2    C3     C4  C5   C6  C7   C8  C9  C10  \\\n",
       "0      0  2733540231  3500392421  4454  15573  11  995   2  176  15  671   \n",
       "1      0  1964843810  1232327635  2081   2547  11  995   2  361  15  802   \n",
       "2      0   660357674  2066571765   602  29581  29  995   0  468  15  758   \n",
       "3      0  2962648192  2373358995  4018  36969  30  995   2    8  15   67   \n",
       "4      0  1822613420   446973819  2081  23457  35  995   0  452  15  821   \n",
       "\n",
       "                                                 CG1              CG2  CG3  \\\n",
       "0  384,382,96,88,185,49,385,268,448,438,279,420,1...              NaN  NaN   \n",
       "1  96,49,385,268,107,438,418,124,357,17,435,130,3...              NaN  NaN   \n",
       "2  170,169,205,204,176,252,243,382,98,220,222,181...              NaN  NaN   \n",
       "3  273,205,383,382,381,219,216,215,225,49,47,54,3...  28071,6916,9108  NaN   \n",
       "4  268,419,357,18,331,59,57,99,154,155,76,412,122...              NaN  NaN   \n",
       "\n",
       "    l1  l2  C11  C12  \n",
       "0   32   0    0  106  \n",
       "1    1   0    0  106  \n",
       "2  119   0    0  103  \n",
       "3    0   0    0  106  \n",
       "4    5   0    0  106  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>CG1</th>\n",
       "      <th>CG2</th>\n",
       "      <th>CG3</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4210358866</td>\n",
       "      <td>3196051971</td>\n",
       "      <td>3336</td>\n",
       "      <td>2094</td>\n",
       "      <td>22</td>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>15</td>\n",
       "      <td>566</td>\n",
       "      <td>176,213,220,222,224,47,422,103,419,74,3,235,23...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2248128334</td>\n",
       "      <td>3994996972</td>\n",
       "      <td>393</td>\n",
       "      <td>16232</td>\n",
       "      <td>52</td>\n",
       "      <td>995</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>821</td>\n",
       "      <td>379,384,98,96,215,224,186,188,183,184,49,50,47...</td>\n",
       "      <td>17179,3883,20334,20333,25423,5318,10989,8668,2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2323433900</td>\n",
       "      <td>1100964395</td>\n",
       "      <td>4454</td>\n",
       "      <td>34157</td>\n",
       "      <td>11</td>\n",
       "      <td>995</td>\n",
       "      <td>2</td>\n",
       "      <td>361</td>\n",
       "      <td>15</td>\n",
       "      <td>672</td>\n",
       "      <td>243,380,269,420,363,31,18,214,331,60,58,306,19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3430094722</td>\n",
       "      <td>1690426382</td>\n",
       "      <td>5919</td>\n",
       "      <td>6384</td>\n",
       "      <td>25</td>\n",
       "      <td>2658</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "      <td>22</td>\n",
       "      <td>722</td>\n",
       "      <td>448,277,276,275,99,154,155,76,412,139,333,332,...</td>\n",
       "      <td>22337,2002</td>\n",
       "      <td>43074,43841,45509,45500,33701,54846,38344,1159...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3531271529</td>\n",
       "      <td>3678868632</td>\n",
       "      <td>1169</td>\n",
       "      <td>26182</td>\n",
       "      <td>30</td>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>15</td>\n",
       "      <td>1131</td>\n",
       "      <td>273,170,205,204,174,173,248,384,382,381,92,97,...</td>\n",
       "      <td>16129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          C1          C2    C3     C4  C5    C6  C7   C8  C9   C10  \\\n",
       "0      1  4210358866  3196051971  3336   2094  22   995   0  361  15   566   \n",
       "1      1  2248128334  3994996972   393  16232  52   995   2    8  15   821   \n",
       "2      1  2323433900  1100964395  4454  34157  11   995   2  361  15   672   \n",
       "3      1  3430094722  1690426382  5919   6384  25  2658   0  390  22   722   \n",
       "4      1  3531271529  3678868632  1169  26182  30   995   0   94  15  1131   \n",
       "\n",
       "                                                 CG1  \\\n",
       "0  176,213,220,222,224,47,422,103,419,74,3,235,23...   \n",
       "1  379,384,98,96,215,224,186,188,183,184,49,50,47...   \n",
       "2  243,380,269,420,363,31,18,214,331,60,58,306,19...   \n",
       "3  448,277,276,275,99,154,155,76,412,139,333,332,...   \n",
       "4  273,170,205,204,174,173,248,384,382,381,92,97,...   \n",
       "\n",
       "                                                 CG2  \\\n",
       "0                                                NaN   \n",
       "1  17179,3883,20334,20333,25423,5318,10989,8668,2...   \n",
       "2                                                NaN   \n",
       "3                                         22337,2002   \n",
       "4                                              16129   \n",
       "\n",
       "                                                 CG3  l1  l2  C11  C12  \n",
       "0                                                NaN   0   0    0  103  \n",
       "1                                                NaN   6   0    0  104  \n",
       "2                                                NaN  48   0    0  106  \n",
       "3  43074,43841,45509,45500,33701,54846,38344,1159...   2   0    1  106  \n",
       "4                                                NaN  23   0    0  104  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label']=test['label']*(-1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all time is -  0.180833101272583 (sec)\n",
      "local time is -  0.06273007392883301 (sec)\n"
     ]
    }
   ],
   "source": [
    "def draw_histograms(dataframe, features, rows, cols):\n",
    "    fig=plt.figure(figsize=(20,20))\n",
    "    for i, feature in enumerate(features):\n",
    "        ax=fig.add_subplot(rows,cols,i+1)\n",
    "        dataframe[feature].hist(bins=20,ax=ax,facecolor='midnightblue')\n",
    "        ax.set_title(feature+\" Distribution\",color='DarkRed')\n",
    "        \n",
    "    fig.tight_layout()  \n",
    "    plt.show()\n",
    "\n",
    "#draw_histograms(all_data[:ntrain],all_data.columns,6,3)\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[1]\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(train['label'].unique())\n",
    "print(test['label'].unique())\n",
    "print(test['label'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 2372  -------  C1 1961\n",
      "C2 1799  -------  C2 1399\n",
      "C3 783  -------  C3 649\n",
      "C4 1363  -------  C4 1091\n",
      "C5 63  -------  C5 64\n",
      "C6 281  -------  C6 225\n",
      "C7 3 [2 0 1]  -------  C7 3 [0 2 1]\n",
      "C8 109  -------  C8 96\n",
      "C9 46  -------  C9 44\n",
      "C10 173  -------  C10 159\n",
      "CG1 2306  -------  CG1 1916\n",
      "CG2 624  -------  CG2 486\n",
      "CG3 369  -------  CG3 242\n",
      "l1 207  -------  l1 222\n",
      "l2 5 [0 1 2 4 5]  -------  l2 8 [ 0  1  3  2 21  6  9  5]\n",
      "C11 2 [0 1]  -------  C11 2 [0 1]\n",
      "C12 8 [106 103 105 104 107 100 101 102]  -------  C12 7 [103 104 106 105 100 107 102]\n",
      "all time is -  0.2457873821258545 (sec)\n",
      "local time is -  0.06495428085327148 (sec)\n"
     ]
    }
   ],
   "source": [
    "# Проверка уникальностей для каждого столбца train\n",
    "for col in all_data.columns:\n",
    "    if len(all_data[col][:ntrain].unique())<11: \n",
    "        print(col, len(all_data[col][:ntrain].unique()),all_data[col][:ntrain].unique() , ' ------- ', col, len(all_data[col][ntrain:].unique()),all_data[col][ntrain:].unique() )\n",
    "    else: print(col, len(all_data[col][:ntrain].unique()), ' ------- ', col, len(all_data[col][ntrain:].unique()))\n",
    "        \n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature ingeniring**\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8999, 381)\n",
      "all time is -  0.6453709602355957 (sec)\n",
      "local time is -  0.3995835781097412 (sec)\n"
     ]
    }
   ],
   "source": [
    "num_cols, cat_cols = list_columns(all_data)\n",
    "\n",
    "for col in num_cols:\n",
    "    for coli in num_cols:\n",
    "        if col != coli:\n",
    "            str1 = col + '_plus_' + coli\n",
    "            str2 = col + '_minus_' + coli\n",
    "            all_data[str1] = all_data[col] + all_data[coli]\n",
    "            all_data[str2] = all_data[col] - all_data[coli]\n",
    "            #print(col, '---', coli)\n",
    "\n",
    "\n",
    "for col in all_data.select_dtypes('object'):\n",
    "    all_data[col] = all_data[col].astype(str)\n",
    "\n",
    "print(all_data.shape)\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8999, 387)\n"
     ]
    }
   ],
   "source": [
    "all_data_str = all_data[['C5','C7', 'C9', 'l2', 'C11', 'C12']]\n",
    "all_data_str.columns = ['C5_str','C7_str', 'C9_str', 'l2_str', 'C11_str', 'C12_str']\n",
    "\n",
    "for col in all_data.select_dtypes('object'):\n",
    "    all_data[col] = all_data[col].astype(str)\n",
    "    \n",
    "for col in all_data_str.columns:\n",
    "    all_data_str[col] = all_data_str[col].astype(str)\n",
    "\n",
    "all_data = pd.concat([all_data, all_data_str], axis=1)\n",
    "\n",
    "print(all_data.shape)\n",
    "num_cols, cat_cols = list_columns(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers**\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135  ---  1135  ---  C5Outlier\n",
      "1203  ---  1203  ---  C6Outlier\n",
      "408  ---  408  ---  C8Outlier\n",
      "1246  ---  1246  ---  C9Outlier\n",
      "1474  ---  1474  ---  l1Outlier\n",
      "87  ---  87  ---  l2Outlier\n",
      "1203  ---  1203  ---  C11Outlier\n",
      "187  ---  187  ---  C12Outlier\n",
      "len of the numeric_feats is:  386\n",
      "len of the categorical_feats is:  9\n",
      "total len of all_data_feats is:  395\n",
      "all time is -  171.19701981544495 (sec)\n",
      "local time is -  170.55164885520935 (sec)\n"
     ]
    }
   ],
   "source": [
    "# Определение вылетов по межквартильному размаху в столбцах с цифрами\n",
    "# Помечаем вылеты через дополнительные столбцы col +'Outlier'\n",
    "\n",
    "#создаем один признак\n",
    "\n",
    "#feature = all_data[num_cols[0]]\n",
    "#создаем функцию, которая возвращает индекс выбросов\n",
    "def indicies_of_outliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3-q1\n",
    "    lower_bond = q1 - (iqr*1.5)\n",
    "    upper_bond = q3 + (iqr*1.5)\n",
    "    return np.where((x > upper_bond) | (x < lower_bond))\n",
    "\n",
    "#применяем функцию\n",
    "# делаем дополнительные бинарные столбы с признаком выброса по каждому числовому столбцу\n",
    "\n",
    "for col in num_cols:   #all_data.columns:\n",
    "    pp = indicies_of_outliers(all_data[col])\n",
    "    list_index = pp[0]\n",
    "    if len(list_index)>1:\n",
    "        name_col = col +'Outlier'\n",
    "        all_data[name_col] = 0\n",
    "        all_data[name_col][list_index] = 1\n",
    "        print(len(list_index), ' --- ', all_data[name_col].sum(), ' --- ', name_col)\n",
    "         \n",
    "columns_len(all_data)\n",
    "#print(all_data['TotRmsOutlier'][:15])\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlations**\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество признаков вначале: 395\n",
      "['C1_plus_C3', 'C1_minus_C3', 'C1_plus_C4', 'C1_minus_C4', 'C1_plus_C5', 'C1_minus_C5', 'C1_plus_C6', 'C1_minus_C6', 'C1_plus_C7', 'C1_minus_C7', 'C1_plus_C8', 'C1_minus_C8', 'C1_plus_C9', 'C1_minus_C9', 'C1_plus_C10', 'C1_minus_C10', 'C1_plus_l1', 'C1_minus_l1', 'C1_plus_l2', 'C1_minus_l2', 'C1_plus_C11', 'C1_minus_C11', 'C1_plus_C12', 'C1_minus_C12', 'C2_plus_C1', 'C2_minus_C1', 'C2_plus_C3', 'C2_minus_C3', 'C2_plus_C4', 'C2_minus_C4', 'C2_plus_C5', 'C2_minus_C5', 'C2_plus_C6', 'C2_minus_C6', 'C2_plus_C7', 'C2_minus_C7', 'C2_plus_C8', 'C2_minus_C8', 'C2_plus_C9', 'C2_minus_C9', 'C2_plus_C10', 'C2_minus_C10', 'C2_plus_l1', 'C2_minus_l1', 'C2_plus_l2', 'C2_minus_l2', 'C2_plus_C11', 'C2_minus_C11', 'C2_plus_C12', 'C2_minus_C12', 'C3_plus_C1', 'C3_minus_C1', 'C3_plus_C2', 'C3_minus_C2', 'C3_plus_C4', 'C3_minus_C4', 'C3_plus_C5', 'C3_minus_C5', 'C3_plus_C7', 'C3_minus_C7', 'C3_plus_C8', 'C3_minus_C8', 'C3_plus_C9', 'C3_minus_C9', 'C3_plus_C10', 'C3_minus_C10', 'C3_plus_l1', 'C3_minus_l1', 'C3_plus_l2', 'C3_minus_l2', 'C3_plus_C11', 'C3_minus_C11', 'C3_plus_C12', 'C3_minus_C12', 'C4_plus_C1', 'C4_minus_C1', 'C4_plus_C2', 'C4_minus_C2', 'C4_plus_C3', 'C4_minus_C3', 'C4_plus_C5', 'C4_minus_C5', 'C4_plus_C6', 'C4_minus_C6', 'C4_plus_C7', 'C4_minus_C7', 'C4_plus_C8', 'C4_minus_C8', 'C4_plus_C9', 'C4_minus_C9', 'C4_plus_C10', 'C4_minus_C10', 'C4_plus_l1', 'C4_minus_l1', 'C4_plus_l2', 'C4_minus_l2', 'C4_plus_C11', 'C4_minus_C11', 'C4_plus_C12', 'C4_minus_C12', 'C5_plus_C1', 'C5_minus_C1', 'C5_plus_C2', 'C5_minus_C2', 'C5_plus_C3', 'C5_minus_C3', 'C5_plus_C4', 'C5_minus_C4', 'C5_plus_C6', 'C5_minus_C6', 'C5_plus_C7', 'C5_minus_C7', 'C5_plus_C8', 'C5_minus_C8', 'C5_plus_C10', 'C5_minus_C10', 'C5_plus_l1', 'C5_minus_l1', 'C5_plus_l2', 'C5_minus_l2', 'C5_plus_C11', 'C5_minus_C11', 'C5_plus_C12', 'C5_minus_C12', 'C6_plus_C1', 'C6_minus_C1', 'C6_plus_C2', 'C6_minus_C2', 'C6_plus_C3', 'C6_minus_C3', 'C6_plus_C4', 'C6_minus_C4', 'C6_plus_C5', 'C6_minus_C5', 'C6_plus_C7', 'C6_minus_C7', 'C6_plus_C8', 'C6_minus_C8', 'C6_plus_C9', 'C6_minus_C9', 'C6_plus_l2', 'C6_minus_l2', 'C6_plus_C11', 'C6_minus_C11', 'C6_plus_C12', 'C6_minus_C12', 'C7_plus_C1', 'C7_minus_C1', 'C7_plus_C2', 'C7_minus_C2', 'C7_plus_C3', 'C7_minus_C3', 'C7_plus_C4', 'C7_minus_C4', 'C7_plus_C5', 'C7_minus_C5', 'C7_plus_C6', 'C7_minus_C6', 'C7_plus_C8', 'C7_minus_C8', 'C7_plus_C9', 'C7_minus_C9', 'C7_plus_C10', 'C7_minus_C10', 'C7_plus_l1', 'C7_minus_l1', 'C7_plus_l2', 'C7_minus_l2', 'C8_plus_C1', 'C8_minus_C1', 'C8_plus_C2', 'C8_minus_C2', 'C8_plus_C3', 'C8_minus_C3', 'C8_plus_C4', 'C8_minus_C4', 'C8_plus_C5', 'C8_minus_C5', 'C8_plus_C6', 'C8_minus_C6', 'C8_plus_C7', 'C8_minus_C7', 'C8_plus_C9', 'C8_minus_C9', 'C8_plus_C10', 'C8_minus_C10', 'C8_plus_l2', 'C8_minus_l2', 'C8_plus_C11', 'C8_minus_C11', 'C8_plus_C12', 'C8_minus_C12', 'C9_plus_C1', 'C9_minus_C1', 'C9_plus_C2', 'C9_minus_C2', 'C9_plus_C3', 'C9_minus_C3', 'C9_plus_C4', 'C9_minus_C4', 'C9_plus_C5', 'C9_minus_C5', 'C9_plus_C6', 'C9_minus_C6', 'C9_plus_C7', 'C9_minus_C7', 'C9_plus_C8', 'C9_minus_C8', 'C9_plus_C10', 'C9_minus_C10', 'C9_plus_l1', 'C9_minus_l1', 'C9_plus_l2', 'C9_minus_l2', 'C9_plus_C11', 'C9_minus_C11', 'C9_plus_C12', 'C9_minus_C12', 'C10_plus_C1', 'C10_minus_C1', 'C10_plus_C2', 'C10_minus_C2', 'C10_plus_C3', 'C10_minus_C3', 'C10_plus_C4', 'C10_minus_C4', 'C10_plus_C5', 'C10_minus_C5', 'C10_plus_C6', 'C10_minus_C6', 'C10_plus_C7', 'C10_minus_C7', 'C10_plus_C8', 'C10_minus_C8', 'C10_plus_C9', 'C10_minus_C9', 'C10_plus_l2', 'C10_minus_l2', 'C10_plus_C11', 'C10_minus_C11', 'C10_plus_C12', 'C10_minus_C12', 'l1_plus_C1', 'l1_minus_C1', 'l1_plus_C2', 'l1_minus_C2', 'l1_plus_C3', 'l1_minus_C3', 'l1_plus_C4', 'l1_minus_C4', 'l1_plus_C5', 'l1_minus_C5', 'l1_plus_C6', 'l1_minus_C6', 'l1_plus_C7', 'l1_minus_C7', 'l1_plus_C8', 'l1_minus_C8', 'l1_plus_C9', 'l1_minus_C9', 'l1_plus_C10', 'l1_minus_C10', 'l1_plus_l2', 'l1_minus_l2', 'l1_plus_C11', 'l1_minus_C11', 'l1_plus_C12', 'l1_minus_C12', 'l2_plus_C1', 'l2_minus_C1', 'l2_plus_C2', 'l2_minus_C2', 'l2_plus_C3', 'l2_minus_C3', 'l2_plus_C4', 'l2_minus_C4', 'l2_plus_C5', 'l2_minus_C5', 'l2_plus_C6', 'l2_minus_C6', 'l2_plus_C7', 'l2_minus_C7', 'l2_plus_C8', 'l2_minus_C8', 'l2_plus_C9', 'l2_minus_C9', 'l2_plus_C10', 'l2_minus_C10', 'l2_plus_l1', 'l2_minus_l1', 'l2_plus_C12', 'l2_minus_C12', 'C11_plus_C1', 'C11_minus_C1', 'C11_plus_C2', 'C11_minus_C2', 'C11_plus_C3', 'C11_minus_C3', 'C11_plus_C4', 'C11_minus_C4', 'C11_plus_C5', 'C11_minus_C5', 'C11_plus_C6', 'C11_minus_C6', 'C11_plus_C7', 'C11_minus_C7', 'C11_plus_C8', 'C11_minus_C8', 'C11_plus_C9', 'C11_minus_C9', 'C11_plus_C10', 'C11_minus_C10', 'C11_plus_l1', 'C11_minus_l1', 'C11_plus_l2', 'C11_minus_l2', 'C11_plus_C12', 'C11_minus_C12', 'C12_plus_C1', 'C12_minus_C1', 'C12_plus_C2', 'C12_minus_C2', 'C12_plus_C3', 'C12_minus_C3', 'C12_plus_C4', 'C12_minus_C4', 'C12_plus_C5', 'C12_minus_C5', 'C12_plus_C6', 'C12_minus_C6', 'C12_plus_C7', 'C12_minus_C7', 'C12_plus_C8', 'C12_minus_C8', 'C12_plus_C9', 'C12_minus_C9', 'C12_plus_C10', 'C12_minus_C10', 'C12_plus_l1', 'C12_minus_l1', 'C12_plus_l2', 'C12_minus_l2', 'C12_plus_C11', 'C12_minus_C11', 'C6Outlier', 'C9Outlier', 'C11Outlier']\n",
      "количество признаков: 395\n",
      "all time is -  212.16904425621033 (sec)\n",
      "local time is -  12.131442070007324 (sec)\n"
     ]
    }
   ],
   "source": [
    "# Correlation matrix\n",
    "def corr_data(features, target):\n",
    "    #обработка высококоррелированных признаков\n",
    "    #создаем корреляционную матрицу\n",
    "    print('количество признаков вначале:', features.shape[1])\n",
    "    corr_matrix = features.corr().abs()\n",
    "\n",
    "    #выбираем верхний треугольник корреляционной матрицы (т.к. нижний симметричный)\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    #находим индекс столбцов признаком с корреляцией больше 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column]>0.95)]\n",
    "    print(to_drop)\n",
    "\n",
    "    # исключаем эти признаки\n",
    "    features.drop(to_drop, axis =1).head(3)\n",
    "\n",
    "    print('количество признаков:', features.shape[1])\n",
    "    \n",
    "\n",
    "corr_data(all_data[:ntrain], y_train)\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отбор признаков, ранжирование по важности**\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 количество наилучших признаков\n",
      "какие категории самые лучшие: \n",
      " [False False False False False False False False False False False  True\n",
      "  True False]\n",
      "ранжирование признака от самого лучшего (1) до самого плохого: \n",
      " [13 12 11 10  4  9  2  5  6  7  8  1  1  3]\n",
      "11    CG2\n",
      "12    CG3\n",
      "6      C7\n",
      "13     l1\n",
      "4      C5\n",
      "7      C8\n",
      "8      C9\n",
      "9     C10\n",
      "10    CG1\n",
      "5      C6\n",
      "3      C4\n",
      "2      C3\n",
      "1      C2\n",
      "0      C1\n",
      "Name: feature, dtype: object\n",
      "all time is -  296.7330951690674 (sec)\n",
      "local time is -  84.56405091285706 (sec)\n"
     ]
    }
   ],
   "source": [
    "#рекурсивное устранение признаков после нормирования признаков\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore', module = 'scipy', message='^internal gelsd')\n",
    "\n",
    "features = all_data[:ntrain][num_cols]\n",
    "target = y_train\n",
    "\n",
    "ols = LinearRegression()\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)\n",
    "\n",
    "print(rfecv.n_features_, 'количество наилучших признаков')\n",
    "print(\"какие категории самые лучшие: \\n\", rfecv.support_)\n",
    "print(\"ранжирование признака от самого лучшего (1) до самого плохого: \\n\", rfecv.ranking_)\n",
    "\n",
    "\n",
    "ii_col = pd.concat([pd.DataFrame(all_data.columns, columns=['feature']), pd.DataFrame(rfecv.ranking_, columns=['ranking'])], axis=1)\n",
    "ii_col = ii_col.sort_values(by=['ranking'])\n",
    "\n",
    "best_features = ii_col[ii_col['ranking']<15]['feature']\n",
    "#print(ii_col)\n",
    "print(best_features)\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocessing pipeline**\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975995199039808\n",
      "0.00025\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-7d0d69c28ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#X_train = preprocessor.fit_transform(X_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "X_train = all_data[:ntrain]\n",
    "X_test = all_data[ntrain:]\n",
    "\n",
    "num_cols, cat_cols = list_columns(all_data)\n",
    "    \n",
    "numeric_features = num_cols\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = cat_cols\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                  ('regressor', LogisticRegression())])  \n",
    "\n",
    "#clf.fit(X_train,y_train)\n",
    "\n",
    "def get_feature_names(self):\n",
    "        return self.X.columns.tolist()\n",
    "    \n",
    "#get_feature_names(clf)\n",
    "\n",
    "#print(X_train.columns.tolist())\n",
    "clf.fit(X_train, y_train)\n",
    "#y_pred = clf.predict(X_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "clf.fit_transform(X_train, y_train)\n",
    "\n",
    "#X_train = preprocessor.fit_transform(X_train)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CG1', 'CG2', 'CG3', 'C5_str', 'C7_str', 'C9_str', 'l2_str', 'C11_str', 'C12_str']\n"
     ]
    }
   ],
   "source": [
    "num_cols, cat_cols = list_columns(all_data)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CG1   CG2   CG3\n",
      "0 40.000 1.000 1.000\n",
      "1 30.000 1.000 1.000\n",
      "2 54.000 1.000 1.000\n",
      "3 46.000 3.000 1.000\n",
      "4 19.000 1.000 1.000\n",
      "len of the numeric_feats is:  29\n",
      "len of the categorical_feats is:  0\n",
      "total len of all_data_feats is:  29\n",
      "all time is -  1.0445668697357178 (sec)\n",
      "local time is -  0.08758139610290527 (sec)\n"
     ]
    }
   ],
   "source": [
    "# Заполнение Nan\n",
    "\n",
    "all_data[\"CG1\"] = all_data[\"CG1\"].fillna(0)\n",
    "all_data[\"CG2\"] = all_data[\"CG2\"].fillna(0)\n",
    "all_data[\"CG3\"] = all_data[\"CG3\"].fillna(0)\n",
    "\n",
    "all_data['C7'] = all_data['C7'].fillna(train['C7'].mode()[0])\n",
    "all_data['l2'] = all_data['l2'].fillna(train['l2'].mode()[0])\n",
    "all_data['C11'] = all_data['C11'].fillna(train['C11'].mode()[0])\n",
    "all_data['C12'] = all_data['C12'].fillna(train['C12'].mode()[0])\n",
    "\n",
    "\n",
    "all_data['CG1'] = all_data['CG1'].apply(lambda x: str(x).count(',')+1) \n",
    "all_data['CG2'] = all_data['CG2'].apply(lambda x: str(x).count(',')+1) \n",
    "all_data['CG3'] = all_data['CG3'].apply(lambda x: str(x).count(',')+1)\n",
    "all_data['CG1'] = all_data['CG1'].apply(lambda x: float(x))\n",
    "all_data['CG2'] = all_data['CG2'].apply(lambda x: float(x))\n",
    "all_data['CG3'] = all_data['CG3'].apply(lambda x: float(x))\n",
    "all_data['CCG3'] = all_data['CG3']+all_data['CG1']\n",
    "all_data['CCG4'] = all_data['CG3']+all_data['CG2']\n",
    "all_data['CCG5'] = all_data['CG1']+all_data['CG2']\n",
    "all_data['C71'] = all_data['C3']*all_data['C4']\n",
    "all_data['C72'] = all_data['C3']*all_data['C8']\n",
    "all_data['C73'] = all_data['C3']*all_data['C5']\n",
    "all_data['C74'] = all_data['C3']*all_data['C6']\n",
    "all_data['C75'] = all_data['C3']*all_data['C7']\n",
    "all_data['C76'] = all_data['C3']*all_data['C9']\n",
    "all_data['C77'] = all_data['C4']*all_data['C5']\n",
    "all_data['C78'] = all_data['C4']*all_data['C6']\n",
    "all_data['C79'] = all_data['C4']*all_data['C7']\n",
    "\n",
    "\n",
    "print(all_data[[\"CG1\", 'CG2', 'CG3']][:5])\n",
    "\n",
    "columns_len(all_data)\n",
    "num_cols, cat_cols = list_columns(all_data)\n",
    "#print(num_cols)\n",
    "\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерирование полиноминальных признаков\n",
    "def polinominal():\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "    polynominal_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "    polynominal_interaction.fit_transform(all_data)\n",
    "\n",
    "    columns_len(all_data)\n",
    "    num_cols, cat_cols = list_columns(all_data)\n",
    "    all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Outliers - определение выбросов через элипс\n",
    "def ellipce_outliers():\n",
    "    from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "    #make detector\n",
    "    outlier_detector = EllipticEnvelope(contamination = .1)\n",
    "    #fit of detector\n",
    "    outlier_detector.fit(all_data[num_cols])\n",
    "    #predict of outliers\n",
    "    p = outlier_detector.predict(all_data[num_cols])\n",
    "    print(p)\n",
    "    print(len(p))\n",
    "    pq = p-1\n",
    "    nn = pq.sum()\n",
    "    print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all time is -  1.240380048751831 (sec)\n",
      "local time is -  0.009525775909423828 (sec)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "(\"unsupported operand type(s) for /: 'str' and 'int'\", 'occurred at index CG1')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-aea1726f6fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Check the skew of all numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mskewed_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSkew in numerical features: \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mskewness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Skew'\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mskewed_feats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6911\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6912\u001b[0m         )\n\u001b[0;32m-> 6913\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6915\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-aea1726f6fd0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Check the skew of all numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mskewed_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSkew in numerical features: \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mskewness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Skew'\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mskewed_feats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mskew\u001b[0;34m(a, axis, bias, nan_policy)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m     \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m     \u001b[0mm3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mmoment\u001b[0;34m(a, moment, axis, nan_policy)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmmnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_moment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m_moment\u001b[0;34m(a, moment, axis)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# Starting point for exponentiation by squares\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0ma_zero_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_zero_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3257\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: (\"unsupported operand type(s) for /: 'str' and 'int'\", 'occurred at index CG1')"
     ]
    }
   ],
   "source": [
    "#Skewed features\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data.apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)\n",
    "\n",
    "#Box Cox Transformation of (highly) skewed features\n",
    "\n",
    "skewness = skewness[abs(skewness) > 0.75]    # My_DS_work - was 0.75 my vers - 0.5\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "    \n",
    "#all_data[skewed_features] = np.log1p(all_data[skewed_features])\n",
    "\n",
    "#Getting dummy categorical features\n",
    "\n",
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)\n",
    "all_data.head()\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '384,382,96,88,185,49,385,268,448,438,279,420,124,123,5,3,17,133,71,409,330,59,57,302,304,395,275,151,113,99,154,155,76,412,139,333,332,335,334,399'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-847ec8b3b73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrfecv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGroupKFold\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '384,382,96,88,185,49,385,268,448,438,279,420,124,123,5,3,17,133,71,409,330,59,57,302,304,395,275,151,113,99,154,155,76,412,139,333,332,335,334,399'"
     ]
    }
   ],
   "source": [
    "#рекурсивное устранение признаков после нормирования признаков через бокс-кокс\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore', module = 'scipy', message='^internal gelsd')\n",
    "\n",
    "features = all_data[:ntrain]\n",
    "target = y_train\n",
    "\n",
    "ols = LinearRegression()\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)\n",
    "\n",
    "print(rfecv.n_features_, 'количество наилучших признаков')\n",
    "print(\"какие категории самые лучшие: \\n\", rfecv.support_)\n",
    "print(\"ранжирование признака от самого лучшего (1) до самого плохого: \\n\", rfecv.ranking_)\n",
    "\n",
    "\n",
    "ii_col = pd.concat([pd.DataFrame(all_data.columns, columns=['feature']), pd.DataFrame(rfecv.ranking_, columns=['ranking'])], axis=1)\n",
    "ii_col = ii_col.sort_values(by=['ranking'])\n",
    "\n",
    "best_features = ii_col[ii_col['ranking']<15]['feature']\n",
    "#print(ii_col)\n",
    "print(best_features)\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4999 samples, validate on 4000 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '205,380,384,382,98,96,220,222,186,188,183,49,47,53,54,52,385,336,337,171,100,279,280,161,74,123,208,15,239,372,341,133,71,409,10,214,202,306,194,322,99,154,155,76,412,122,139,333,332,335,334,137,399'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-a505489b0ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     validation_data = (all_data[ntrain:], y_test))\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpredict_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2915\u001b[0m                 array_vals.append(\n\u001b[1;32m   2916\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2917\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '205,380,384,382,98,96,220,222,186,188,183,49,47,53,54,52,385,336,337,171,100,279,280,161,74,123,208,15,239,372,341,133,71,409,10,214,202,306,194,322,99,154,155,76,412,122,139,333,332,335,334,137,399'"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape = (len(all_data.columns),)))\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "network.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer = 'rmsprop',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = network.fit(\n",
    "    all_data[:ntrain],\n",
    "    y_train,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    "    batch_size = 100,\n",
    "    validation_data = (all_data[ntrain:], y_test))\n",
    "\n",
    "predict_target = network.predict(all_data[ntrain:])\n",
    "\n",
    "\n",
    "\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-fd589e2524bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#y_test= y_test.apply(lambda x: float(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(y_test[:2].values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(predict_target[:2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_loss neuron network'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_target' is not defined"
     ]
    }
   ],
   "source": [
    "predict_target = predict_target[:,0]\n",
    "#y_test= y_test.apply(lambda x: float(x))\n",
    "#print(y_test[:2].values)\n",
    "#print(predict_target[:2])\n",
    "print('log_loss neuron network', log_loss(y_test, predict_target, labels=labels))\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '96,215,52,385,268,416,449,104,279,280,161,74,124,123,357,235,31,18,202,57,308,152,351,150,113,324,323,99,154,155,76,412,122,200,329,139,333,332,335,334,399'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-6dd384d142a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlog_loss_scorer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2017\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mntrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_loss_scorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RandomForestClassifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '96,215,52,385,268,416,449,104,279,280,161,74,124,123,357,235,31,18,202,57,308,152,351,150,113,324,323,99,154,155,76,412,122,200,329,139,333,332,335,334,399'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "log_loss_scorer=make_scorer(log_loss, needs_proba=True)\n",
    "rf=RandomForestClassifier(n_estimators=100, random_state=2017, n_jobs=-1)\n",
    "scores=cross_val_score(rf, X=all_data[:ntrain], y=y_train, cv=3, scoring=log_loss_scorer, verbose=1)\n",
    "print(scores, 'RandomForestClassifier')\n",
    "\n",
    "#разделение на 2 класса через опорно-векторную машину на ядерных функциях\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', class_weight = 'balanced', random_state=0, C=1, probability=True)\n",
    "scores=cross_val_score(rf, X=all_data[:ntrain], y=y_train, cv=3, scoring=log_loss_scorer, verbose=1)\n",
    "print(scores, 'SVC')\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08552275 0.06807468 0.08586559] ExtraTreesClassifier\n",
      "all time is -  10.288185358047485 (sec)\n",
      "local time is -  0.9901361465454102 (sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(\n",
    "        n_estimators = 50,\n",
    "        max_depth = None,\n",
    "        max_features = 'auto',\n",
    "        criterion='entropy',\n",
    "        n_jobs = -1,\n",
    "        random_state = 0)\n",
    "        \n",
    "    \n",
    "scores=cross_val_score(rf, X=all_data[:ntrain], y=y_train, cv=3, scoring=log_loss_scorer, verbose=1)\n",
    "print(scores, 'ExtraTreesClassifier')\n",
    "\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(page 231)отбор наилучших моделей из нескольких обучающихся алгоритмов\n",
    "\n",
    "def find_best_algor():\n",
    "    import numpy as np\n",
    "    from sklearn import datasets\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    #задать случайное число для генератора псевдослучайных чисел\n",
    "    np.random.seed(0)\n",
    "\n",
    "    features = all_data[best_features][:ntrain]\n",
    "    target = y_train\n",
    "\n",
    "\n",
    "    #создать конвейер\n",
    "    pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "    #создать словарь вариантов обучающихся алгоритмов и их гиперпараметров\n",
    "    search_space = [{'classifier': [LogisticRegression()],\n",
    "                    'classifier__penalty': ['l1', 'l2'],\n",
    "                    'classifier__C': np.logspace(0, 4, 10)},\n",
    "                    {'classifier': [RandomForestClassifier()],\n",
    "                     'classifier__n_estimators': [10, 100, 1000],\n",
    "                     'classifier__max_features': [1, 2, 3]}]\n",
    "    #создать объект решеточного поиска\n",
    "    gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "    best_model = gridsearch.fit(features, target)\n",
    "    #взглянуть на лучшую модель и ее параметры\n",
    "    best_model.best_estimator_.get_params()['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(page 238)оценивание результативности после отбора модели\n",
    "def val_scormodel():\n",
    "    from sklearn import linear_model\n",
    "    from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "    logistic = linear_model.LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                       multi_class='warn', n_jobs=-1, penalty='l1',\n",
    "                       random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "    #создать диапазон из 20 вариантов значений для С\n",
    "    C = np.logspace(0, 4, 20)\n",
    "    #создать словарь вариантов гиперпараметров\n",
    "    hyperparameters = dict(C=C)\n",
    "    #создать объект решеточного поиска\n",
    "    gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=0)\n",
    "    #выполнить вложенную перекрестную проверку и выдать среднюю оценку\n",
    "    cross_val_score(gridsearch, features, target).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def any_any():\n",
    "    features = all_data[best_features][:ntrain]\n",
    "    target = y_train\n",
    "    test_pred = all_data[best_features][ntrain:]\n",
    "\n",
    "    #создать объект предобработки, который включает\n",
    "    #признаки стандартного шкалировщика и объект РСА\n",
    "    preprocess = FeatureUnion([('std', StandardScaler()), ('pca', PCA())])\n",
    "    #создать конвейер\n",
    "    pipe = Pipeline([('preprocess', preprocess),\n",
    "                    ('classifier', LogisticRegression())])\n",
    "    #создать пространство вариантов значений\n",
    "    search_space = [{'preprocess__pca__n_components': [1, 2, 3],\n",
    "                     'classifier__penalty': ['l1', 'l2'],\n",
    "                     'classifier__C': np.logspace(0, 4, 10)}]\n",
    "\n",
    "    #создать объект решеточного поиска\n",
    "    clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "    best_model = clf.fit(features, target)\n",
    "    #взглянуть на лучшую модель и ее параметры\n",
    "    best_model.best_estimator_.get_params()['preprocess__pca__n_components']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[1 1 1 ... 1 1 1]\n",
      "(4999, 50) (4999, 1)\n",
      "(4000, 50) (4000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "train_size = ntrain\n",
    "X = all_data\n",
    "y_test = test['label'].values\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "y = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_test)], ignore_index=True) #.reset_index(drop=True))\n",
    "\n",
    "print(X[:train_size].shape, y[:train_size].shape)\n",
    "print(X[train_size:].shape, y[train_size:].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599454\n",
      "all time is -  13.377265930175781 (sec)\n",
      "local time is -  3.089080572128296 (sec)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logistic = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=-1, penalty='l1',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "\n",
    "logistic.fit(X[:train_size], y[:train_size])\n",
    "log_pred = logistic.predict_log_proba(X[train_size:])\n",
    "#log_pred1 = logistic.predict(X[train_size:])\n",
    "#print(log_pred)\n",
    "#print(log_pred1)\n",
    "#print(\"Log-loss: %.3f (logistic)\" % log_loss(y[train_size:], log_pred1))\n",
    "print(log_loss(y_test, log_pred, labels=labels))\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "log_pred1 = pd.DataFrame(log_pred)\n",
    "log_pred1 = log_pred1[log_pred1.columns[0]]\n",
    "#print(log_pred)\n",
    "#print(log_pred1)\n",
    "\n",
    "\n",
    "log_pred1.to_csv('sample_submission.csv', header=0, index=False)\n",
    "#log_pred1.to_csv('sample_submission3.csv',index=False)\n",
    "\n",
    "print('finish')\n",
    "#print('nrows_test', nrows_test)\n",
    "#print('log_pred', len(log_pred), 'shape', log_pred.shape)\n",
    "#print('log_pred1', len(log_pred1), 'shape', log_pred1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[1 1 1 ... 1 1 1]\n",
      "(4999, 50) (4999, 1)\n",
      "(4000, 50) (4000, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ea5bf858b398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mgp_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianProcessClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mRBF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgp_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m print(\"Log Marginal Likelihood (initial): %.3f\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/gaussian_process/gpc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    632\u001b[0m                                  % self.multi_class)\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/gaussian_process/gpc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    210\u001b[0m             optima = [self._constrained_optimization(obj_func,\n\u001b[1;32m    211\u001b[0m                                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                                      self.kernel_.bounds)]\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# Additional runs are performed from log-uniform chosen initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/gaussian_process/gpc.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mtheta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvergence_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvergence_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 warnings.warn(\"fmin_l_bfgs_b terminated abnormally with the \"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/gaussian_process/gpc.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0;32m--> 204\u001b[0;31m                         theta, eval_gradient=True)\n\u001b[0m\u001b[1;32m    205\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/gaussian_process/gpc.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# XXX: Get rid of the np.diag() in the next line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_sr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcho_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_sr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Line 7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_sr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Line 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;31m# Line 9: (use einsum to compute np.diag(C.T.dot(C))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0ms_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ij, ij -> j'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b, sym_pos, lower, overwrite_a, overwrite_b, debug, check_finite, assume_a, transposed)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_solve_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         x, info = getrs(lu, ipvt, b1,\n\u001b[0;32m--> 218\u001b[0;31m                         trans=trans, overwrite_b=overwrite_b)\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0m_solve_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mrcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgecon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "train_size = ntrain\n",
    "X = all_data\n",
    "y_test = test['label'].values\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "y = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_test)], ignore_index=True) #.reset_index(drop=True))\n",
    "\n",
    "print(X[:train_size].shape, y[:train_size].shape)\n",
    "print(X[train_size:].shape, y[train_size:].shape)\n",
    "\n",
    "\n",
    "# Specify Gaussian Processes with fixed and optimized hyperparameters\n",
    "gp_fix = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0),\n",
    "                                   optimizer=None)\n",
    "gp_fix.fit(X[:train_size], y[:train_size])\n",
    "\n",
    "gp_opt = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0))\n",
    "gp_opt.fit(X[:train_size], y[:train_size])\n",
    "\n",
    "print(\"Log Marginal Likelihood (initial): %.3f\"\n",
    "      % gp_fix.log_marginal_likelihood(gp_fix.kernel_.theta))\n",
    "print(\"Log Marginal Likelihood (optimized): %.3f\"\n",
    "      % gp_opt.log_marginal_likelihood(gp_opt.kernel_.theta))\n",
    "\n",
    "print(\"Accuracy: %.3f (initial) %.3f (optimized)\"\n",
    "      % (accuracy_score(y[:train_size], gp_fix.predict(X[:train_size])),\n",
    "         accuracy_score(y[:train_size], gp_opt.predict(X[:train_size]))))\n",
    "print(\"Log-loss: %.3f (initial) %.3f (optimized)\"\n",
    "      % (log_loss(y[:train_size], gp_fix.predict_proba(X[:train_size], labels=labels)[:, 1]),\n",
    "         log_loss(y[:train_size], gp_opt.predict_proba(X[:train_size], labels=labels)[:, 1])))\n",
    "\n",
    "\n",
    "tik_local = mytime(tik_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_pred = gp_fix.predict_proba(X[train_size:])\n",
    "opt_pred = gp_opt.predict_proba(X[train_size:])\n",
    "print(fix_pred)\n",
    "print(opt_pred)\n",
    "\n",
    "fix_pred = pd.DataFrame(fix_pred)\n",
    "opt_pred = pd.DataFrame(opt_pred)\n",
    "fix_pred.to_csv('sample_submission2.csv',index=False)  #'sample_submission.csv'\n",
    "opt_pred.to_csv('sample_submission3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
